// Пакет llm реализует абстракцию провайдеров языковых моделей (LLM).
// Поддерживаются как локальные (Ollama), так и облачные провайдеры
// (OpenAI, Anthropic, YandexGPT, GigaChat).
package llm

// ChatRequest — универсальный запрос к любому LLM-провайдеру.
// Содержит имя модели, историю сообщений, список инструментов (tools)
// и флаг стриминга. Используется всеми провайдерами одинаково —
// каждый провайдер конвертирует его в свой внутренний формат.
type ChatRequest struct {
	Model    string    `json:"model"`           // Имя модели (например, "gpt-4o", "claude-sonnet-4-20250514", "yandexgpt")
	Messages []Message `json:"messages"`        // История сообщений диалога (system, user, assistant, tool)
	Tools    []Tool    `json:"tools,omitempty"` // Список доступных инструментов для вызова моделью
	Stream   bool      `json:"stream"`          // Включить потоковую передачу ответа (поддерживается только Ollama)
}

// ChatResponse — универсальный ответ от любого LLM-провайдера.
// Содержит текстовый контент ответа, список вызовов инструментов (если модель
// решила использовать tool calling), и имя использованной модели.
type ChatResponse struct {
	Content   string     `json:"content"`              // Текстовый ответ модели
	ToolCalls []ToolCall `json:"tool_calls,omitempty"` // Вызовы инструментов, запрошенные моделью
	Model     string     `json:"model"`                // Имя модели, которая сгенерировала ответ
}

// ModelDetail — детальная информация о модели провайдера.
// Включает идентификатор, статус доступности, информацию о ценах
// и подсказку по активации (что нужно сделать для использования недоступной модели).
// Используется в UI для визуального разделения:
//   - Яркие (is_available=true) = модели, доступные прямо сейчас (есть баланс, бесплатные токены, активная подписка)
//   - Тусклые (is_available=false) = модели, которые нельзя использовать (нужно пополнить баланс, оформить подписку и т.д.)
//   - При нажатии на тусклую модель пользователь видит activation_hint — инструкцию, что сделать для активации
type ModelDetail struct {
	ID             string `json:"id"`              // Идентификатор модели (например, "openai/gpt-4o", "GigaChat-Max")
	IsAvailable    bool   `json:"is_available"`    // true = модель доступна прямо сейчас (можно использовать)
	PricingInfo    string `json:"pricing_info"`    // Краткое описание цены (например, "Бесплатно", "$0.01/1K токенов")
	ActivationHint string `json:"activation_hint"` // Инструкция: что сделать, чтобы активировать недоступную модель
}

// ProviderInfo — информация о зарегистрированном провайдере.
// Используется для отображения в UI списка доступных провайдеров и их моделей.
type ProviderInfo struct {
	Name   string   `json:"name"`   // Уникальное имя провайдера (например, "openai", "anthropic")
	Models []string `json:"models"` // Список доступных моделей у данного провайдера
}

// ChatProvider — основной интерфейс для всех LLM-провайдеров.
// Каждый провайдер (Ollama, OpenAI, Anthropic, YandexGPT, GigaChat, OpenRouter)
// должен реализовать этот интерфейс. Это позволяет единообразно
// работать с любым провайдером через реестр (Registry).
//
// Методы:
//   - Chat: отправляет запрос к LLM и возвращает ответ
//   - ListModels: возвращает список идентификаторов доступных моделей
//   - ListModelsDetailed: возвращает детальную информацию о моделях (цены, бесплатность)
//   - Name: возвращает уникальное имя провайдера для идентификации в реестре
type ChatProvider interface {
	Chat(req *ChatRequest) (*ChatResponse, error) // Отправить запрос к модели и получить ответ
	ListModels() ([]string, error)                // Получить список идентификаторов моделей
	ListModelsDetailed() ([]ModelDetail, error)   // Получить детальную информацию о моделях (цены, бесплатность, активация)
	Name() string                                 // Получить имя провайдера
}
