# Тестовые задачи для проверки Агента-Администратора

Каждая задача — это полная инструкция, которую Админ должен выполнить целиком без подсказок.
Задачи расположены по возрастанию сложности. Каждая следующая сложнее предыдущей.

---

## Задача 1: Инвентаризация системы

Собери полную информацию о системе и сохрани в файл.

1. Создай директорию ~/system-inventory/
2. Собери информацию о системе и сохрани в ~/system-inventory/system_info.txt:
   - Версия ОС (cat /etc/os-release)
   - Архитектура процессора (uname -m), количество ядер (nproc), модель (lscpu | grep "Model name")
   - Объём оперативной памяти (free -h)
   - Список дисков и разделов с объёмами (lsblk, df -h)
   - Сетевые интерфейсы и IP-адреса (ip addr show)
   - Список установленных пакетов (dpkg --list | wc -l для количества)
   - Время работы системы (uptime)
3. Собери информацию о сетевых портах и сохрани в ~/system-inventory/network_ports.txt:
   - Все прослушиваемые порты (ss -tlnp)
   - Активные соединения (ss -tnp)
4. Создай сводный файл ~/system-inventory/SUMMARY.md с кратким описанием системы в формате Markdown
5. Проверь что все файлы созданы и содержат данные (ls -la ~/system-inventory/ и head каждого файла)

Критерий успеха: все три файла созданы, содержат актуальные данные, SUMMARY.md читаем и структурирован.

---

## Задача 2: Управление пользователями и правами доступа

Настрой систему пользователей и прав для проектной команды.

1. Создай группу developers: sudo groupadd developers
2. Создай группу devops: sudo groupadd devops
3. Создай пользователя dev1 с домашней директорией и оболочкой bash, добавь в группу developers:
   sudo useradd -m -s /bin/bash -G developers dev1
4. Создай пользователя dev2 аналогично в группу developers
5. Создай пользователя ops1 в группу devops
6. Создай директорию проекта /opt/project/ с правами:
   - Владелец: root
   - Группа: developers
   - Права: rwxrwxr-x (775)
   - Установи SGID бит: chmod g+s /opt/project/
7. Создай директорию /opt/project/deploy/ с правами:
   - Группа: devops
   - Права: rwxrwx--- (770)
8. Создай файл /opt/project/README.md с текстом "Проектная документация"
9. Проверь все права: ls -la /opt/project/
10. Проверь что dev1 может писать в /opt/project/ но не в /opt/project/deploy/
11. Проверь что ops1 может писать в /opt/project/deploy/
12. Сохрани отчёт о проверках в /opt/project/access_report.txt

Критерий успеха: пользователи созданы, группы настроены, права работают корректно, отчёт содержит результаты проверок.

---

## Задача 3: Настройка мониторинга процессов и ресурсов

Создай систему мониторинга ресурсов с логированием и алертами.

1. Создай директорию ~/monitoring/
2. Напиши скрипт ~/monitoring/resource_monitor.sh который:
   - Собирает загрузку CPU (top -bn1 | grep "Cpu(s)")
   - Собирает использование RAM (free -m)
   - Собирает использование дисков (df -h)
   - Собирает топ-5 процессов по CPU (ps aux --sort=-%cpu | head -6)
   - Собирает топ-5 процессов по RAM (ps aux --sort=-%mem | head -6)
   - Записывает всё в лог ~/monitoring/logs/resource_YYYYMMDD_HHMMSS.log с временной меткой
   - Если CPU > 80% или RAM > 90% — записывает ALERT в ~/monitoring/alerts.log
3. Сделай скрипт исполняемым: chmod +x ~/monitoring/resource_monitor.sh
4. Запусти скрипт и проверь что лог создан и содержит данные
5. Напиши скрипт ~/monitoring/cleanup_logs.sh который удаляет логи старше 7 дней
6. Напиши скрипт ~/monitoring/report.sh который:
   - Считает количество алертов за последние 24 часа
   - Показывает среднюю загрузку CPU из логов
   - Выводит итоговый отчёт
7. Запусти resource_monitor.sh 3 раза с паузой 2 секунды, затем запусти report.sh
8. Проверь что все скрипты работают без ошибок

Критерий успеха: три скрипта созданы и работают, логи записываются, отчёт формируется корректно.

---

## Задача 4: Настройка Git-репозитория с хуками и автоматизацией

Создай Git-репозиторий с pre-commit хуками, шаблонами и автоматизацией.

1. Создай директорию ~/git-project/ и инициализируй Git-репозиторий
2. Настрой Git:
   - git config user.name "Admin Agent"
   - git config user.email "admin@agentcore.local"
3. Создай структуру проекта:
   - src/ — исходный код
   - tests/ — тесты
   - docs/ — документация
   - scripts/ — скрипты автоматизации
4. Создай .gitignore с правилами:
   - *.log, *.tmp, *.swp
   - node_modules/, __pycache__/, .env
   - build/, dist/
5. Создай pre-commit хук (.git/hooks/pre-commit) который:
   - Проверяет что нет файлов с .env в коммите
   - Проверяет что нет файлов больше 1MB
   - Проверяет что все .sh файлы имеют shebang (#!/bin/bash)
   - Выводит список изменённых файлов
   - Сделай хук исполняемым
6. Создай шаблон коммит-сообщения (.gitmessage):
   - Формат: [тип]: краткое описание
   - Типы: feat, fix, docs, refactor, test, chore
   - Настрой: git config commit.template .gitmessage
7. Создай скрипт scripts/auto_commit.sh который:
   - Проверяет есть ли изменения (git status --porcelain)
   - Если есть — делает git add и commit с автоматическим сообщением включающим дату
   - Логирует действие в scripts/commit_log.txt
8. Создай файл src/main.py с простым "Hello World"
9. Создай файл tests/test_main.py с простым тестом
10. Сделай первый коммит со всеми файлами
11. Создай файл src/utils.py, запусти auto_commit.sh и проверь что коммит создан
12. Проверь git log --oneline

Критерий успеха: репозиторий настроен, хуки работают, auto_commit создаёт коммиты, git log показывает историю.

---

## Задача 5: Резервное копирование с ротацией и верификацией

Создай полноценную систему резервного копирования с ротацией, верификацией и восстановлением.

1. Создай структуру:
   - ~/backup-system/source/ — исходные данные для бэкапа
   - ~/backup-system/backups/ — хранилище бэкапов
   - ~/backup-system/restore/ — директория для тестового восстановления
   - ~/backup-system/logs/ — логи бэкапов
2. Создай тестовые данные в source/:
   - config/app.conf с содержимым конфигурации (минимум 10 строк)
   - data/database.sql с SQL-дампом (минимум 20 строк CREATE TABLE, INSERT)
   - data/users.csv с таблицей пользователей (минимум 5 записей)
   - docs/README.md с документацией проекта
3. Напиши скрипт ~/backup-system/backup.sh который:
   - Создаёт tar.gz архив source/ с именем backup_YYYYMMDD_HHMMSS.tar.gz
   - Вычисляет SHA256 хеш архива и сохраняет в .sha256 файл рядом
   - Записывает размер архива, количество файлов, дату в logs/backup.log
   - Проверяет целостность архива (tar -tzf)
   - Выводит статус: УСПЕХ или ОШИБКА
4. Напиши скрипт ~/backup-system/rotate.sh который:
   - Оставляет только последние 5 бэкапов
   - Удаляет старые бэкапы и их .sha256 файлы
   - Логирует удалённые файлы в logs/rotation.log
5. Напиши скрипт ~/backup-system/verify.sh который:
   - Проверяет SHA256 хеш каждого бэкапа
   - Пробует распаковать архив во временную директорию
   - Сравнивает количество файлов с оригиналом
   - Выводит отчёт о целостности каждого бэкапа
6. Напиши скрипт ~/backup-system/restore.sh который:
   - Принимает имя бэкапа как аргумент
   - Проверяет его SHA256 хеш
   - Распаковывает в restore/
   - Сравнивает содержимое restore/ с source/ используя diff -r
   - Выводит результат восстановления
7. Запусти backup.sh 3 раза, затем verify.sh, затем restore.sh с последним бэкапом
8. Проверь что восстановленные данные идентичны оригиналу

Критерий успеха: бэкапы создаются, хеши совпадают, верификация проходит, восстановление даёт идентичные данные.

---

## Задача 6: Настройка сетевого окружения и файрвола

Настрой сетевую безопасность системы с правилами файрвола, проверкой портов и мониторингом.

1. Создай директорию ~/network-security/
2. Проведи аудит текущего состояния:
   - Сохрани текущие правила iptables в ~/network-security/iptables_before.txt
   - Сохрани список открытых портов в ~/network-security/open_ports_before.txt
   - Сохрани активные сетевые соединения в ~/network-security/connections_before.txt
3. Напиши скрипт ~/network-security/firewall_setup.sh который:
   - Сохраняет текущие правила как бэкап
   - Устанавливает политику по умолчанию: INPUT DROP, FORWARD DROP, OUTPUT ACCEPT
   - Разрешает loopback интерфейс (lo)
   - Разрешает established и related соединения
   - Разрешает SSH (порт 22)
   - Разрешает HTTP (порт 80) и HTTPS (порт 443)
   - Разрешает DNS (порт 53, TCP и UDP)
   - Разрешает ICMP (ping)
   - Разрешает порты приложения: 3000, 5173, 8080, 8082, 8083 (Agent Core NG)
   - Логирует заблокированные пакеты
   - ВНИМАНИЕ: НЕ применяет правила (только генерирует скрипт), чтобы не заблокировать доступ
4. Напиши скрипт ~/network-security/port_scan.sh который:
   - Сканирует локальные порты 1-1024 и 3000-9000
   - Определяет какой процесс слушает каждый открытый порт
   - Классифицирует порты: known (известный сервис) / unknown (неизвестный)
   - Сохраняет результат в ~/network-security/port_scan_report.txt
5. Напиши скрипт ~/network-security/connection_monitor.sh который:
   - Мониторит новые входящие соединения каждые 5 секунд (3 итерации)
   - Логирует IP-адреса, порты и процессы в ~/network-security/connection_log.txt
   - Отмечает подозрительные соединения (на нестандартных портах)
6. Создай файл ~/network-security/SECURITY_POLICY.md описывающий:
   - Какие порты открыты и зачем
   - Какие правила файрвола настроены
   - Процедуру реагирования на подозрительную активность
7. Запусти port_scan.sh и connection_monitor.sh, проверь результаты

Критерий успеха: скрипты созданы, аудит проведён, отчёты сформированы, политика безопасности документирована.

---

## Задача 7: Автоматизация развёртывания приложения

Создай полный пайплайн развёртывания приложения с проверками, откатом и уведомлениями.

1. Создай структуру проекта:
   - ~/deploy-pipeline/app/ — исходный код приложения
   - ~/deploy-pipeline/releases/ — релизы (симлинк current → актуальный релиз)
   - ~/deploy-pipeline/shared/ — общие файлы (конфиги, логи)
   - ~/deploy-pipeline/scripts/ — скрипты деплоя
   - ~/deploy-pipeline/logs/ — логи деплоя
2. Создай приложение ~/deploy-pipeline/app/:
   - app.py: Flask/HTTP сервер на Python (или простой HTTP сервер) который:
     * Слушает порт 9090
     * Отвечает на GET / с JSON {"status": "ok", "version": "VERSION"}
     * Отвечает на GET /health с {"healthy": true}
     * Читает VERSION из файла version.txt
   - version.txt: "1.0.0"
   - requirements.txt: flask (или без зависимостей если используешь http.server)
   - tests/test_app.py: тест который проверяет что / возвращает 200
3. Напиши скрипт ~/deploy-pipeline/scripts/deploy.sh который:
   - Принимает версию как аргумент (например: ./deploy.sh 1.1.0)
   - Создаёт директорию релиза releases/release_VERSION_TIMESTAMP/
   - Копирует файлы приложения в директорию релиза
   - Обновляет version.txt с новой версией
   - Запускает тесты (если есть)
   - Обновляет симлинк releases/current → новый релиз
   - Копирует shared/ конфиги в релиз
   - Логирует деплой в logs/deploy.log с временем, версией, статусом
   - При ошибке — откатывается на предыдущий релиз
4. Напиши скрипт ~/deploy-pipeline/scripts/rollback.sh который:
   - Находит предыдущий релиз
   - Переключает симлинк current на предыдущий релиз
   - Логирует откат
5. Напиши скрипт ~/deploy-pipeline/scripts/healthcheck.sh который:
   - Проверяет что приложение отвечает на /health
   - Проверяет что версия в ответе совпадает с ожидаемой
   - Если проверка не проходит — вызывает rollback.sh
6. Создай конфиг shared/config.json с настройками приложения
7. Выполни деплой версий 1.0.0, 1.1.0, 1.2.0
8. Проверь что releases/current указывает на 1.2.0
9. Выполни rollback и проверь что current указывает на 1.1.0
10. Проверь logs/deploy.log — должна быть вся история

Критерий успеха: три версии задеплоены, откат работает, логи ведутся, healthcheck проверяет состояние.

---

## Задача 8: Настройка агентов системы Agent Core NG

Настрой агентов системы, подбери оптимальные модели и проверь их работоспособность.

1. Используй инструмент list_models_for_role для каждой роли (admin, coder, novice):
   - Получи список доступных моделей с рекомендациями
   - Запиши результаты в ~/agent-config/model_analysis.md
2. Используй get_agent_info для каждого агента (admin, coder, novice):
   - Запиши текущие настройки каждого агента
   - Сохрани в ~/agent-config/current_config.md
3. Проанализируй рекомендации и выбери оптимальные модели:
   - Для admin: модель с поддержкой tools + большим размером (13B+)
   - Для coder: модель с поддержкой tools + специализация на коде
   - Для novice: компактная модель для простых задач
4. Используй configure_agent для настройки каждого агента:
   - Установи выбранную модель
   - Установи провайдера (ollama для локальных)
5. Проверь настройки повторно через get_agent_info
6. Делегируй тестовую задачу Кодеру через call_coder:
   - Задача: "Напиши скрипт на Python который считает факториал числа 10 и выводит результат"
7. Делегируй тестовую задачу Послушнику через call_novice:
   - Задача: "Посчитай сколько файлов в директории /tmp/ и выведи результат"
8. Сохрани итоговый отчёт в ~/agent-config/setup_report.md:
   - Какие модели выбраны и почему
   - Результаты тестовых задач
   - Рекомендации по оптимизации

Критерий успеха: агенты настроены с оптимальными моделями, тестовые задачи выполнены, отчёт сформирован.

---

## Задача 9: Создание системы непрерывной интеграции

Создай локальную CI-систему с автоматическим тестированием, сборкой и отчётами.

1. Создай структуру:
   - ~/ci-system/projects/ — проекты для CI
   - ~/ci-system/pipelines/ — описания пайплайнов
   - ~/ci-system/artifacts/ — артефакты сборки
   - ~/ci-system/reports/ — отчёты о сборках
   - ~/ci-system/engine/ — движок CI
2. Создай тестовый проект ~/ci-system/projects/sample-app/:
   - Инициализируй Git-репозиторий
   - Создай src/calculator.py с функциями add, subtract, multiply, divide
   - Создай tests/test_calculator.py с юнит-тестами для каждой функции
   - Создай Makefile с целями: test, lint, build, clean
   - Создай requirements.txt (pytest, pylint)
   - Сделай начальный коммит
3. Создай формат описания пайплайна ~/ci-system/pipelines/sample-app.yaml (текстовый):
   - Этап 1: checkout — получить код из репозитория
   - Этап 2: install — установить зависимости
   - Этап 3: lint — проверить стиль кода
   - Этап 4: test — запустить тесты
   - Этап 5: build — собрать проект (создать архив)
   - Этап 6: report — сформировать отчёт
4. Напиши скрипт ~/ci-system/engine/run_pipeline.sh который:
   - Принимает путь к пайплайну как аргумент
   - Парсит этапы из YAML-подобного файла
   - Выполняет каждый этап последовательно
   - При ошибке на этапе — останавливает пайплайн, фиксирует FAILED
   - Записывает stdout/stderr каждого этапа в отдельный файл
   - Создаёт артефакт сборки в artifacts/ с номером сборки
   - Формирует HTML-отчёт в reports/ с результатами всех этапов
   - Поддерживает параметры: --project, --pipeline, --build-number
5. Напиши скрипт ~/ci-system/engine/trigger.sh который:
   - Проверяет Git-репозиторий проекта на новые коммиты
   - Если есть новые коммиты — запускает run_pipeline.sh
   - Логирует запуски в ~/ci-system/logs/trigger.log
6. Запусти пайплайн для sample-app:
   ./engine/run_pipeline.sh --project projects/sample-app --pipeline pipelines/sample-app.yaml --build-number 1
7. Внеси изменение в sample-app (добавь функцию power в calculator.py и тест)
8. Закоммить и запусти пайплайн повторно (build-number 2)
9. Проверь что в artifacts/ есть два артефакта, в reports/ два отчёта

Критерий успеха: CI-движок работает, пайплайн выполняет все этапы, артефакты и отчёты создаются, trigger обнаруживает новые коммиты.

---

## Задача 10: Полная автоматизация инфраструктуры с оркестрацией

Создай систему оркестрации, которая объединяет мониторинг, бэкапы, деплой, CI и самовосстановление в единую автоматизированную инфраструктуру.

1. Создай мастер-директорию ~/infrastructure/:
   - orchestrator/ — центральный оркестратор
   - services/ — описания сервисов
   - state/ — текущее состояние системы
   - events/ — очередь событий
   - actions/ — автоматические действия
   - dashboards/ — дашборды состояния
2. Создай описания сервисов в services/ (JSON-файлы для каждого сервиса):
   - agent-service.json: порт 8083, healthcheck URL, зависимости, команда запуска
   - api-gateway.json: порт 8080, healthcheck, зависимости (agent-service, tools-service)
   - tools-service.json: порт 8082, healthcheck, зависимости
   - web-ui.json: порт 5173, healthcheck, зависимости (api-gateway)
3. Напиши оркестратор ~/infrastructure/orchestrator/orchestrator.sh который:
   - Читает описания всех сервисов из services/
   - Проверяет состояние каждого сервиса (healthcheck)
   - Записывает состояние в state/current_state.json:
     * Имя сервиса, статус (running/stopped/degraded), время проверки
     * Использование CPU и RAM процессом сервиса
     * Время последнего успешного healthcheck
   - Обнаруживает аномалии:
     * Сервис не отвечает на healthcheck
     * CPU > 80% у сервиса
     * RAM > 1GB у сервиса
   - При аномалии создаёт событие в events/ (JSON-файл с деталями)
   - Запускает соответствующее действие из actions/
4. Напиши действия в actions/:
   - restart_service.sh: перезапуск упавшего сервиса
   - scale_alert.sh: уведомление (запись в лог) о высокой нагрузке
   - dependency_check.sh: проверка зависимостей сервиса перед перезапуском
   - backup_state.sh: бэкап текущего состояния перед изменениями
5. Напиши скрипт ~/infrastructure/orchestrator/dependency_resolver.sh который:
   - Строит граф зависимостей между сервисами
   - Определяет правильный порядок запуска
   - Определяет каскадные эффекты при падении сервиса
   - Сохраняет граф в state/dependency_graph.txt
6. Напиши дашборд ~/infrastructure/dashboards/status.sh который:
   - Выводит таблицу состояния всех сервисов
   - Показывает последние 5 событий
   - Показывает последние 5 действий
   - Выводит общий статус системы: HEALTHY / DEGRADED / CRITICAL
7. Напиши скрипт ~/infrastructure/orchestrator/init.sh который:
   - Запускает все сервисы в правильном порядке (по зависимостям)
   - Ожидает healthcheck каждого сервиса перед запуском следующего
   - Логирует процесс инициализации
8. Запусти оркестратор для проверки текущего состояния
9. Запусти дашборд и проверь вывод
10. Запусти dependency_resolver.sh и проверь граф зависимостей
11. Сохрани полный отчёт в ~/infrastructure/INFRASTRUCTURE_REPORT.md:
    - Архитектура системы
    - Граф зависимостей
    - Текущее состояние
    - Список автоматических действий
    - План масштабирования

Критерий успеха: оркестратор проверяет все сервисы, граф зависимостей построен, дашборд показывает состояние, события и действия обрабатываются, отчёт сформирован.
